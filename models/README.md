<h1 align='center'>Models</h1>
<p align="center">A selection of the best models are available for <a href="https://drive.google.com/open?id=1-ufDf4UOIwmA3AQQjaSOBgT0Lmtj4TgD">download from my Google Drive</a>. After downloading simply store the pre-trained model directories in the <a href="experiments"><code>experiments</code></a> directory.</p>
<p align="center">A summary of the models and their results is below</p>
<p align="center">TODO Add summary table</p>


<p align="center">Models evaluated on the Pascal VOC, MS-COCO or ImageNet-DET dataset use the image based metrics: Box Area's - <b>S</b>mall <code>&lt;32</code>, <b>M</b>edium <code>32-96</code>, <b>L</b>arge <code>&gt;96</code>. While models evaluated on the ImageNet-VID datasets use the video based metrics: Box Area's - <b>S</b>mall <code>&lt;50</code>, <b>M</b>edium <code>50-150</code>, <b>L</b>arge <code>&gt;150</code> - Instance's Speed (motion IoU) - <b>SL</b>ow <code>&gt;0.9</code>, <b>MO</b>derate <code>0.7-0.9</code>, <b>FA</b>st <code>&lt;0.7</code></p>

<h2></h2>
<h2 align="center">Framewise CNNs</h2>
<h3 align="center">Baselines</h3>

<p align="center">These models are trained and tested on their respective datasets. The Pascal VOC and MS-COCO models are taken from the <a href="https://gluon-cv.mxnet.io/model_zoo/detection.html">GluonCV Model Zoo</a></p>


<p align="center">.......</p>
<h3 align="center">ImageNet-VID Finetuning</h3>
<p align="center">Coming Soon</p>


<p align="center">.......</p>
<h3 align="center">Combined Dataset Training</h3>
<p align="center">Coming Soon</p>

<h2></h2>
<h2 align="center">Temporal CNNs</h2>
<p align="center">.......</p>
<h3 align="center">Channel Concatenation</h3>
<p align="center">Coming Soon</p>

<p align="center">.......</p>
<h3 align="center">R(2+1)D CNN</h3>
<p align="center">Coming Soon</p>

<p align="center">.......</p>
<h3 align="center">Hierarchical 3D</h3>
<p align="center">Coming Soon</p>
